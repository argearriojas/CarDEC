{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W7GlQylhmlTz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jlakkis/anaconda3/envs/DESCImpute/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version.  The public classes are available in the top-level namespace.\n",
      "  from pandas.core.index import RangeIndex\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-694ed6864c69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\"\"\"CarDEC Package\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mCarDEC_API\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCarDEC_API\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/CarDEC/CarDEC/CarDEC_API.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mCarDEC_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnormalize_scanpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mCarDEC_MainModel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCarDEC_Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mCarDEC_count_decoder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcount_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\"\"\"Broadly useful python packages\"\"\"\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "from shutil import move\n",
    "import warnings\n",
    "\n",
    "\"\"\"Machine learning and single cell packages\"\"\"\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import adjusted_rand_score as ari, normalized_mutual_info_score as nmi\n",
    "import scanpy as sc\n",
    "from anndata import AnnData\n",
    "\n",
    "\"\"\"CarDEC Package\"\"\"\n",
    "from CarDEC_API import CarDEC_API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W6V3sY2ZmlT2"
   },
   "outputs": [],
   "source": [
    "\"\"\"Miscellaneous useful functions\"\"\"\n",
    "\n",
    "def read_macaque(path):\n",
    "    \"\"\"A function to read and preprocess the macaque data\"\"\"\n",
    "    adata = sc.read(path)\n",
    "    sc.pp.filter_cells(adata, min_genes=0)\n",
    "    sc.pp.filter_genes(adata, min_cells=30)\n",
    "    \n",
    "    adata = adata[adata.obs['n_genes'] < 2500, :]\n",
    "    \n",
    "    return(adata)\n",
    "\n",
    "def purity_score(y_true, y_pred):\n",
    "    \"\"\"A function to compute cluster purity\"\"\"\n",
    "    # compute contingency matrix (also called confusion matrix)\n",
    "    contingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
    "\n",
    "    return np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix)\n",
    "\n",
    "def find_resolution(adata_, n_clusters, random = 0): \n",
    "    adata = adata_.copy()\n",
    "    obtained_clusters = -1\n",
    "    iteration = 0\n",
    "    resolutions = [0., 1000.]\n",
    "    \n",
    "    while obtained_clusters != n_clusters and iteration < 50:\n",
    "        current_res = sum(resolutions)/2\n",
    "        sc.tl.louvain(adata, resolution = current_res, random_state = random)\n",
    "        labels = adata.obs['louvain']\n",
    "        obtained_clusters = len(np.unique(labels))\n",
    "        \n",
    "        if obtained_clusters < n_clusters:\n",
    "            resolutions[0] = current_res\n",
    "        else:\n",
    "            resolutions[1] = current_res\n",
    "        \n",
    "        iteration = iteration + 1\n",
    "        \n",
    "    return current_res\n",
    "\n",
    "metrics_ = [ari, nmi, purity_score]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G4jy5VRpmlT4"
   },
   "source": [
    "In the following cell, we read in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fFc4M-jXmlT5"
   },
   "outputs": [],
   "source": [
    "\"\"\"Read and normalize the data\"\"\"\n",
    "adata = read_macaque(\"macaque_bc.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7VB6HrpjmlT7"
   },
   "source": [
    "Now, intialize the CarDEC class. Doing so will normalize the dataset. The results will be stored in an anndata object, referenced by CarDEC.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mqRy8GM-mlT7",
    "outputId": "330d1a6f-11a5-4e0f-edd5-9dd19b13538f"
   },
   "outputs": [],
   "source": [
    "\"\"\"Args: \n",
    "    1. adata is the dataframe to work on\n",
    "    2. weights_dir: A directory in which to save weights for both the autoencoder pretrain step, and for the finetuned\n",
    "    CarDEC model. Weights are also loaded from this directory. If the directory doesn't exist, then it will be \n",
    "    created from scratch.\n",
    "    3. batch_key is the key in adata.obs that identifies the vector of cell batch assignments\n",
    "    4. n_high_var is the number of features to treat as highly variable. These features drive clustering. The top\n",
    "       n_high_var highly variable genes are identified with scanpy, using within batch variation\n",
    "    5. LVG: If True, then denoise low variance features too. Else, only denoise the high variance genes.\n",
    "\"\"\"\n",
    "\n",
    "CarDEC = CarDEC_API(adata, weights_dir = \"weights_dir/CarDEC_LVG Weights\", batch_key = \"sample\", n_high_var = 2000, LVG = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oSSGPTBomlT-"
   },
   "source": [
    "## Fit the CarDEC Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g1jq8qDrmlT-"
   },
   "source": [
    "Now, build the model. If weights for the autoencoder do not exist in the weights directory, the autoencoder will be pretrained and its weights will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xq9DBHAPmlT_",
    "outputId": "c34a4265-3280-46f0-edfb-8d35278e8376",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "CarDEC.build_model(n_clusters = 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xYspwXkYmlUB"
   },
   "source": [
    "Now, call the make_inference method to finetune CarDEC. Doing so will finetune the model, and then produce denoised features on the zscore scale. If weights for the full model are already saved in the weights directory, these weights will be loaded, rather than training the full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PlKxD3AFmlUB",
    "outputId": "935ccf2a-518f-4424-82ea-8502fb12367d"
   },
   "outputs": [],
   "source": [
    "CarDEC.make_inference()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IlLVdlhAmlUD"
   },
   "source": [
    "To get denoised features on the count scale, call the model_counts method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tO7AUQClmlUD",
    "outputId": "66ea5dd3-2570-4ea2-f1ea-40cf50a81100"
   },
   "outputs": [],
   "source": [
    "CarDEC.model_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EwvcE7m0mlUF"
   },
   "source": [
    "As mentioned before, the output is accessed via CarDEC.dataset. Let's look at the output structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Umf6ohsmlUG",
    "outputId": "34ce3aa6-2b27-4ccc-f9ec-2ae33d8e1cae"
   },
   "outputs": [],
   "source": [
    "print(\"The overall structure of the output is: \\n\")\n",
    "print(CarDEC.dataset)\n",
    "\n",
    "CarDEC.dataset.X #The main layer of the output object contains the original counts\n",
    "CarDEC.dataset.layers['denoised'] #These are the denoised features, on the zscore scale\n",
    "CarDEC.dataset.layers['denoised counts'] #These are the denoised features, on the count scale\n",
    "CarDEC.dataset.var['Variance Type'] #This is a vector that informs which genes are high variance and which are low variance\n",
    "CarDEC.dataset.obsm['embedding'] #This is the CarDEC low-dimensional embedding after finetuning.\n",
    "CarDEC.dataset.obsm['precluster denoised'] #This is the matrix of feature zscores denoised with the pretrained autoencoder.\n",
    "CarDEC.dataset.obsm['precluster embedding'] #This is the latent embedding from the pretrained autoencoder.\n",
    "CarDEC.dataset.obsm['initial assignments'] #This is a vector of cluster assignments from running louvain after the pretrain step\n",
    "\n",
    "\"\"\"Example, this is how to get the matrix of denoised counts for only high variance genes\"\"\"\n",
    "HVG_denoised = deepcopy(CarDEC.dataset.layers['denoised counts'][:, CarDEC.dataset.var['Variance Type'] == 'HVG'])\n",
    "\n",
    "\"\"\"Example, this is how to get the matrix of denoised counts for only low variance genes\"\"\"\n",
    "LVG_denoised = deepcopy(CarDEC.dataset.layers['denoised counts'][:, CarDEC.dataset.var['Variance Type'] == 'LVG'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vI3e95rzmlUH"
   },
   "source": [
    "## Working with the embedding and cluster assignments\n",
    "\n",
    "Here, I demonstrate how to access the latent embedding of CarDEC and how to use it for UMAP visualization. I also demonstrate how to get the CarDEC cluster assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XmTpr7-3mlUI",
    "outputId": "98754edc-6a74-4bb6-9deb-311b5c797627"
   },
   "outputs": [],
   "source": [
    "\"\"\"Get the predicted cluster assignments and compute cluster accuracy metrics\"\"\"\n",
    "\n",
    "embedded = deepcopy(CarDEC.dataset.obsm['embedding']) #The latent embedding numpy array\n",
    "\n",
    "q = deepcopy(CarDEC.dataset.obsm['cluster memberships']) #The cluster membership numpy array\n",
    "labels = np.argmax(q, axis=1)\n",
    "labels = [str(x) for x in labels]\n",
    "\n",
    "true_celltype = list(CarDEC.dataset.obs['cluster']) #Note: all obs properties from the inputted adata are inherited by the output\n",
    "\n",
    "print(\"CarDEC Clustering Results\")\n",
    "ARI, NMI, Purity = [metric(CarDEC.dataset.obs['cluster'], labels) for metric in metrics_]\n",
    "\n",
    "print (\"ARI = {0:.4f}\".format(ARI)) \n",
    "print (\"NMI = {0:.4f}\".format(NMI)) \n",
    "print (\"Purity = {0:.4f}\".format(Purity))\n",
    "\n",
    "\"\"\"Create a scanpy AnnData object with the latent embedding as the matrix, to perform scanpy UMAP embedding\"\"\"\n",
    "formatting = AnnData(embedded)\n",
    "formatting.obs[\"cell_type\"] = list(CarDEC.dataset.obs['cluster'])\n",
    "formatting.obs[\"predicted\"] = list(labels)\n",
    "formatting.obs[\"sample\"] = list(CarDEC.dataset.obs['sample'])\n",
    "formatting.obs[\"macaque_id\"] = list(CarDEC.dataset.obs['macaque_id'])\n",
    "\n",
    "sc.pp.neighbors(formatting, n_neighbors = 15, use_rep = 'X')\n",
    "sc.tl.umap(formatting)\n",
    "sc.pl.umap(formatting, color = [\"predicted\", \"cell_type\", \"sample\", \"macaque_id\"], return_fig = True)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IK1go6R7mlUK",
    "outputId": "e3329d66-2d39-4e8d-80eb-5135b5b58ede"
   },
   "outputs": [],
   "source": [
    "\"\"\"Get the predicted labels and compute adjusted rand score for the precluster embedding\"\"\"\n",
    "\n",
    "preclust_emb = deepcopy(CarDEC.dataset.obsm['precluster embedding'])\n",
    "\n",
    "formatting = AnnData(preclust_emb)\n",
    "sc.pp.neighbors(formatting, n_neighbors = 15, use_rep = 'X')\n",
    "res = find_resolution(formatting, 11)\n",
    "sc.tl.louvain(formatting, resolution = res)\n",
    "\n",
    "print(str(len(np.unique(labels))) + \" Clusters Detected\")\n",
    "\n",
    "labels = formatting.obs['louvain']\n",
    "type_strings = list(CarDEC.dataset.obs['cluster'])\n",
    "\n",
    "ARI, NMI, Purity = [metric(CarDEC.dataset.obs['cluster'], labels) for metric in metrics_]\n",
    "\n",
    "print(\"Pretrained Autoencoder Clustering Results\")\n",
    "print (\"ARI = {0:.4f}\".format(ARI))\n",
    "print (\"NMI = {0:.4f}\".format(NMI))\n",
    "print (\"Purity = {0:.4f}\".format(Purity))\n",
    "\n",
    "formatting.obs[\"cell_type\"] = list(CarDEC.dataset.obs['cluster'])\n",
    "formatting.obs[\"predicted\"] = list(labels)\n",
    "formatting.obs[\"sample\"] = list(CarDEC.dataset.obs['sample'])\n",
    "formatting.obs[\"region\"] = list(CarDEC.dataset.obs['region'])\n",
    "formatting.obs[\"macaque_id\"] = list(CarDEC.dataset.obs['macaque_id'])\n",
    "sc.tl.umap(formatting)\n",
    "sc.pl.umap(formatting, color = [\"predicted\", \"cell_type\", \"sample\", \"macaque_id\"], return_fig=True)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IVu9ALdImlUM"
   },
   "source": [
    "## Working with the denoised counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yRO6u6WImlUN"
   },
   "source": [
    "Here I work with the denoised counts. I demonstrate the use of the denoised counts for UMAP embedding and louvain clustering with scanpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SWPVmFA7mlUN",
    "outputId": "51a54c37-6c54-49e7-ea50-1018c2cb6a29",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Assessing denoised Counts\"\"\"\n",
    "\n",
    "temporary = AnnData(deepcopy(CarDEC.dataset.layers['denoised counts']))\n",
    "temporary.obs = CarDEC.dataset.obs\n",
    "temporary.obs['cell_type'] = temporary.obs['cluster']\n",
    "\n",
    "sc.pp.normalize_total(temporary)\n",
    "sc.pp.log1p(temporary)\n",
    "sc.pp.scale(temporary)\n",
    "\n",
    "sc.tl.pca(temporary, svd_solver='arpack')\n",
    "sc.pp.neighbors(temporary, n_neighbors = 15)\n",
    "\n",
    "res = find_resolution(temporary, 11)\n",
    "sc.tl.louvain(temporary, resolution = res)\n",
    "temporary.obs['cluster assignment'] = temporary.obs['louvain']\n",
    "\n",
    "sc.tl.umap(temporary)\n",
    "sc.pl.umap(temporary, color = [\"cell_type\", \"cluster assignment\", \"sample\", \"macaque_id\"], return_fig = True)\n",
    "\n",
    "ARI, NMI, Purity = [metric(temporary.obs['cell_type'], temporary.obs['cluster assignment']) for metric in metrics_]\n",
    "\n",
    "print(\"CarDEC Denoising Results using all denoised counts\")\n",
    "print (\"ARI = {0:.4f}\".format(ARI)) \n",
    "print (\"NMI = {0:.4f}\".format(NMI)) \n",
    "print (\"Purity = {0:.4f}\".format(Purity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jxyDR9PMmlUQ"
   },
   "source": [
    "## Working with only the high variance denoised counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0l-ysdibmlUQ",
    "outputId": "29da88e3-e95e-4f4c-bf60-7c4f45ad39af"
   },
   "outputs": [],
   "source": [
    "\"\"\"Assessing HVG denoised Counts\"\"\"\n",
    "\n",
    "temporary = AnnData(deepcopy(CarDEC.dataset.layers['denoised counts'][:, CarDEC.dataset.var['Variance Type'] == 'HVG']))\n",
    "temporary.obs = CarDEC.dataset.obs\n",
    "temporary.obs['cell_type'] = temporary.obs['cluster']\n",
    "\n",
    "sc.pp.normalize_total(temporary)\n",
    "sc.pp.log1p(temporary)\n",
    "sc.pp.scale(temporary)\n",
    "\n",
    "sc.tl.pca(temporary, svd_solver='arpack')\n",
    "sc.pp.neighbors(temporary, n_neighbors = 15)\n",
    "\n",
    "res = find_resolution(temporary, 11)\n",
    "sc.tl.louvain(temporary, resolution = res)\n",
    "temporary.obs['cluster assignment'] = temporary.obs['louvain']\n",
    "\n",
    "sc.tl.umap(temporary)\n",
    "sc.pl.umap(temporary, color = [\"cell_type\", \"cluster assignment\", \"sample\", \"macaque_id\"], return_fig = True)\n",
    "\n",
    "ARI, NMI, Purity = [metric(temporary.obs['cell_type'], temporary.obs['cluster assignment']) for metric in metrics_]\n",
    "\n",
    "print(\"Clustering high variance denoised counts\")\n",
    "print (\"ARI = {0:.4f}\".format(ARI)) \n",
    "print (\"NMI = {0:.4f}\".format(NMI)) \n",
    "print (\"Purity = {0:.4f}\".format(Purity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c3qF2CcgmlUT"
   },
   "source": [
    "## Working with only the low variance denoised counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kyRPYOBEmlUT",
    "outputId": "d0a60f95-eb90-45e1-f418-38c3bef6a367"
   },
   "outputs": [],
   "source": [
    "\"\"\"Assessing LVG denoised Counts\"\"\"\n",
    "\n",
    "temporary = AnnData(deepcopy(CarDEC.dataset.layers['denoised counts'][:, CarDEC.dataset.var['Variance Type'] == 'LVG']))\n",
    "temporary.obs = CarDEC.dataset.obs\n",
    "temporary.obs['cell_type'] = temporary.obs['cluster']\n",
    "\n",
    "sc.pp.normalize_total(temporary)\n",
    "sc.pp.log1p(temporary)\n",
    "sc.pp.scale(temporary)\n",
    "\n",
    "sc.tl.pca(temporary, svd_solver='arpack')\n",
    "sc.pp.neighbors(temporary, n_neighbors = 15)\n",
    "\n",
    "res = find_resolution(temporary, 11)\n",
    "sc.tl.louvain(temporary, resolution = res)\n",
    "temporary.obs['cluster assignment'] = temporary.obs['louvain']\n",
    "\n",
    "sc.tl.umap(temporary)\n",
    "sc.pl.umap(temporary, color = [\"cell_type\", \"cluster assignment\", \"sample\", \"macaque_id\"], return_fig = True)\n",
    "\n",
    "ARI, NMI, Purity = [metric(temporary.obs['cell_type'], temporary.obs['cluster assignment']) for metric in metrics_]\n",
    "\n",
    "print(\"Clustering low variance denoised counts\")\n",
    "print (\"ARI = {0:.4f}\".format(ARI)) \n",
    "print (\"NMI = {0:.4f}\".format(NMI)) \n",
    "print (\"Purity = {0:.4f}\".format(Purity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JS67IQMFmlUV"
   },
   "source": [
    "## Working with the denoised counts on the zscore scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GdvpnXvpmlUW",
    "outputId": "ae347641-1303-47d4-ec3d-e08e69cecaf5"
   },
   "outputs": [],
   "source": [
    "\"\"\"Assessing denoised zscore features\"\"\"\n",
    "\n",
    "temporary = AnnData(deepcopy(CarDEC.dataset.layers['denoised']))\n",
    "temporary.obs = CarDEC.dataset.obs\n",
    "temporary.obs['cell_type'] = temporary.obs['cluster']\n",
    "\n",
    "sc.tl.pca(temporary, svd_solver='arpack')\n",
    "sc.pp.neighbors(temporary, n_neighbors = 15)\n",
    "\n",
    "res = find_resolution(temporary, 11)\n",
    "sc.tl.louvain(temporary, resolution = res)\n",
    "temporary.obs['cluster assignment'] = temporary.obs['louvain']\n",
    "\n",
    "sc.tl.umap(temporary)\n",
    "sc.pl.umap(temporary, color = [\"cell_type\", \"cluster assignment\", \"sample\", \"macaque_id\"], return_fig = True)\n",
    "\n",
    "ARI, NMI, Purity = [metric(temporary.obs['cell_type'], temporary.obs['cluster assignment']) for metric in metrics_]\n",
    "\n",
    "print(\"CarDEC Denoising Results using all denoised features\")\n",
    "print (\"ARI = {0:.4f}\".format(ARI)) \n",
    "print (\"NMI = {0:.4f}\".format(NMI)) \n",
    "print (\"Purity = {0:.4f}\".format(Purity))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CarDEC Macaque Basic Example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:DESCImpute]",
   "language": "python",
   "name": "conda-env-DESCImpute-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
